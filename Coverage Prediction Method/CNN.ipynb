{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823ba00d-aee2-43d4-a3ed-ea90724196f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 18:42:38.854924: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Concatenate, concatenate, Conv1D, MaxPooling1D,Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy, mean_squared_error\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b76788cd-8745-478e-8fd6-3ff2fce4757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6ea723-4b6e-4ee3-9e83-75d80bd1ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (72440, 5000, 1) (72440,)\n",
      "Validation: (8944, 5000, 1) (8944,)\n",
      "Test: (8049, 5000, 1) (8049,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"./mutations_coverage_prediction.npz\")\n",
    "max_len = 5000\n",
    "X, Y = data['x'], data['y']\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(data['x'], data['y'], test_size=0.1)\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.1)\n",
    "del X\n",
    "del Y\n",
    "del data\n",
    "\n",
    "print ('Training:', train_x.shape, train_y.shape)\n",
    "print ('Validation:', val_x.shape, val_y.shape)\n",
    "print ('Test:', test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f2c816-6cdf-456d-976d-0afd923915d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 4998, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 2499, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 319872)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 319873    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,385\n",
      "Trainable params: 320,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 18:42:46.457306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-07 18:42:46.477469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-07 18:42:46.477642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-07 18:42:46.477981: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 18:42:46.479677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-07 18:42:46.479829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-07 18:42:46.479951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-07 18:42:46.769082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-07 18:42:46.769247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-07 18:42:46.769375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-07 18:42:46.769476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6718 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "2023-03-07 18:42:46.769679: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, kernel_size=3, activation='relu', input_shape=train_x[0].shape))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "adam = Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=adam, loss=mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3741e62-c797-4356-b168-c004b92dc2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 18:42:48.114386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2023-03-07 18:42:48.770608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2264/2264 [==============================] - ETA: 0s - loss: 17.2896\n",
      "Epoch 1: val_loss improved from inf to 10.66315, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 13s 5ms/step - loss: 17.2896 - val_loss: 10.6631\n",
      "Epoch 2/100\n",
      "2259/2264 [============================>.] - ETA: 0s - loss: 11.2142\n",
      "Epoch 2: val_loss improved from 10.66315 to 9.67740, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 11.2074 - val_loss: 9.6774\n",
      "Epoch 3/100\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 9.8177\n",
      "Epoch 3: val_loss did not improve from 9.67740\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 9.8177 - val_loss: 9.8633\n",
      "Epoch 4/100\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 10.5184\n",
      "Epoch 4: val_loss improved from 9.67740 to 9.35617, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 10.5184 - val_loss: 9.3562\n",
      "Epoch 5/100\n",
      "2253/2264 [============================>.] - ETA: 0s - loss: 9.9962 \n",
      "Epoch 5: val_loss improved from 9.35617 to 8.49258, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 9.9949 - val_loss: 8.4926\n",
      "Epoch 6/100\n",
      "2261/2264 [============================>.] - ETA: 0s - loss: 9.7306\n",
      "Epoch 6: val_loss did not improve from 8.49258\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 9.7315 - val_loss: 13.3847\n",
      "Epoch 7/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 8.8955\n",
      "Epoch 7: val_loss did not improve from 8.49258\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 8.8882 - val_loss: 10.1614\n",
      "Epoch 8/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 8.5753\n",
      "Epoch 8: val_loss did not improve from 8.49258\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 8.5733 - val_loss: 8.4937\n",
      "Epoch 9/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 8.2789\n",
      "Epoch 9: val_loss improved from 8.49258 to 8.21157, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 8.2773 - val_loss: 8.2116\n",
      "Epoch 10/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 8.1625\n",
      "Epoch 10: val_loss improved from 8.21157 to 8.03944, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 8.1620 - val_loss: 8.0394\n",
      "Epoch 11/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 7.9859\n",
      "Epoch 11: val_loss did not improve from 8.03944\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.9863 - val_loss: 8.5792\n",
      "Epoch 12/100\n",
      "2261/2264 [============================>.] - ETA: 0s - loss: 7.7960\n",
      "Epoch 12: val_loss did not improve from 8.03944\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.7917 - val_loss: 8.1406\n",
      "Epoch 13/100\n",
      "2263/2264 [============================>.] - ETA: 0s - loss: 7.6186\n",
      "Epoch 13: val_loss improved from 8.03944 to 7.87266, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 7.6189 - val_loss: 7.8727\n",
      "Epoch 14/100\n",
      "2254/2264 [============================>.] - ETA: 0s - loss: 7.6281\n",
      "Epoch 14: val_loss did not improve from 7.87266\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.6230 - val_loss: 8.0089\n",
      "Epoch 15/100\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 7.4206\n",
      "Epoch 15: val_loss improved from 7.87266 to 7.82797, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 7.4206 - val_loss: 7.8280\n",
      "Epoch 16/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 7.2864\n",
      "Epoch 16: val_loss did not improve from 7.82797\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.2820 - val_loss: 7.9956\n",
      "Epoch 17/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 7.2743\n",
      "Epoch 17: val_loss did not improve from 7.82797\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.2761 - val_loss: 8.0529\n",
      "Epoch 18/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 7.2502\n",
      "Epoch 18: val_loss did not improve from 7.82797\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.2517 - val_loss: 7.9464\n",
      "Epoch 19/100\n",
      "2261/2264 [============================>.] - ETA: 0s - loss: 7.1305\n",
      "Epoch 19: val_loss improved from 7.82797 to 7.77832, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.1312 - val_loss: 7.7783\n",
      "Epoch 20/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 7.1493\n",
      "Epoch 20: val_loss improved from 7.77832 to 7.73925, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.1463 - val_loss: 7.7393\n",
      "Epoch 21/100\n",
      "2263/2264 [============================>.] - ETA: 0s - loss: 7.1128\n",
      "Epoch 21: val_loss improved from 7.73925 to 7.67333, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.1132 - val_loss: 7.6733\n",
      "Epoch 22/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 7.0259\n",
      "Epoch 22: val_loss did not improve from 7.67333\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 7.0312 - val_loss: 8.1670\n",
      "Epoch 23/100\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 6.9532\n",
      "Epoch 23: val_loss did not improve from 7.67333\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.9532 - val_loss: 7.7723\n",
      "Epoch 24/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.9271\n",
      "Epoch 24: val_loss improved from 7.67333 to 7.58738, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.9267 - val_loss: 7.5874\n",
      "Epoch 25/100\n",
      "2259/2264 [============================>.] - ETA: 0s - loss: 6.9250\n",
      "Epoch 25: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.9233 - val_loss: 7.6417\n",
      "Epoch 26/100\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 6.8848\n",
      "Epoch 26: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.8848 - val_loss: 7.6558\n",
      "Epoch 27/100\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 6.8445\n",
      "Epoch 27: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.8445 - val_loss: 7.7694\n",
      "Epoch 28/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.8528\n",
      "Epoch 28: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.8505 - val_loss: 8.1079\n",
      "Epoch 29/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.8076\n",
      "Epoch 29: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.8056 - val_loss: 7.6650\n",
      "Epoch 30/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.7685\n",
      "Epoch 30: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.7696 - val_loss: 7.6547\n",
      "Epoch 31/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 6.7299\n",
      "Epoch 31: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.7285 - val_loss: 7.6540\n",
      "Epoch 32/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 6.7007\n",
      "Epoch 32: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.7003 - val_loss: 7.6619\n",
      "Epoch 33/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.6904\n",
      "Epoch 33: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.6893 - val_loss: 7.7212\n",
      "Epoch 34/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.6570\n",
      "Epoch 34: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.6597 - val_loss: 7.6241\n",
      "Epoch 35/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.6844\n",
      "Epoch 35: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.6816 - val_loss: 7.8218\n",
      "Epoch 36/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.6165\n",
      "Epoch 36: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.6139 - val_loss: 7.6140\n",
      "Epoch 37/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.5729\n",
      "Epoch 37: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.5715 - val_loss: 7.6804\n",
      "Epoch 38/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.5729\n",
      "Epoch 38: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.5725 - val_loss: 7.5931\n",
      "Epoch 39/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.5861\n",
      "Epoch 39: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.5848 - val_loss: 7.6511\n",
      "Epoch 40/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 6.5470\n",
      "Epoch 40: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.5477 - val_loss: 7.6554\n",
      "Epoch 41/100\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 6.5008\n",
      "Epoch 41: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.5008 - val_loss: 7.6140\n",
      "Epoch 42/100\n",
      "2261/2264 [============================>.] - ETA: 0s - loss: 6.5096\n",
      "Epoch 42: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.5083 - val_loss: 7.6945\n",
      "Epoch 43/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 6.4839\n",
      "Epoch 43: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.4836 - val_loss: 7.6314\n",
      "Epoch 44/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 6.4782\n",
      "Epoch 44: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.4763 - val_loss: 7.7918\n",
      "Epoch 45/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 6.5094\n",
      "Epoch 45: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.5083 - val_loss: 7.6431\n",
      "Epoch 46/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.4461\n",
      "Epoch 46: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.4473 - val_loss: 7.6747\n",
      "Epoch 47/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.4310\n",
      "Epoch 47: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.4290 - val_loss: 7.6411\n",
      "Epoch 48/100\n",
      "2254/2264 [============================>.] - ETA: 0s - loss: 6.4063\n",
      "Epoch 48: val_loss did not improve from 7.58738\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.4072 - val_loss: 7.7300\n",
      "Epoch 49/100\n",
      "2263/2264 [============================>.] - ETA: 0s - loss: 6.4376\n",
      "Epoch 49: val_loss improved from 7.58738 to 7.57164, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.4370 - val_loss: 7.5716\n",
      "Epoch 50/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.4108\n",
      "Epoch 50: val_loss did not improve from 7.57164\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.4148 - val_loss: 7.6612\n",
      "Epoch 51/100\n",
      "2261/2264 [============================>.] - ETA: 0s - loss: 6.3673\n",
      "Epoch 51: val_loss did not improve from 7.57164\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.3674 - val_loss: 7.6563\n",
      "Epoch 52/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 6.3616\n",
      "Epoch 52: val_loss did not improve from 7.57164\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.3573 - val_loss: 7.6060\n",
      "Epoch 53/100\n",
      "2261/2264 [============================>.] - ETA: 0s - loss: 6.3672\n",
      "Epoch 53: val_loss improved from 7.57164 to 7.56959, saving model to best_model_cnn_checkpoint.h5\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.3682 - val_loss: 7.5696\n",
      "Epoch 54/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.3723\n",
      "Epoch 54: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.3716 - val_loss: 7.6341\n",
      "Epoch 55/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.3333\n",
      "Epoch 55: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.3338 - val_loss: 7.6092\n",
      "Epoch 56/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.2846\n",
      "Epoch 56: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2847 - val_loss: 7.6173\n",
      "Epoch 57/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.3159\n",
      "Epoch 57: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.3170 - val_loss: 7.6838\n",
      "Epoch 58/100\n",
      "2259/2264 [============================>.] - ETA: 0s - loss: 6.2805\n",
      "Epoch 58: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2839 - val_loss: 7.6738\n",
      "Epoch 59/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 6.2942\n",
      "Epoch 59: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2938 - val_loss: 7.6077\n",
      "Epoch 60/100\n",
      "2263/2264 [============================>.] - ETA: 0s - loss: 6.2955\n",
      "Epoch 60: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2958 - val_loss: 7.6092\n",
      "Epoch 61/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 6.2643\n",
      "Epoch 61: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2651 - val_loss: 7.6409\n",
      "Epoch 62/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.2499\n",
      "Epoch 62: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2513 - val_loss: 7.7186\n",
      "Epoch 63/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.2490\n",
      "Epoch 63: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2484 - val_loss: 7.7941\n",
      "Epoch 64/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 6.2283\n",
      "Epoch 64: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2297 - val_loss: 7.7859\n",
      "Epoch 65/100\n",
      "2262/2264 [============================>.] - ETA: 0s - loss: 6.2395\n",
      "Epoch 65: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2380 - val_loss: 7.6397\n",
      "Epoch 66/100\n",
      "2263/2264 [============================>.] - ETA: 0s - loss: 6.2500\n",
      "Epoch 66: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2503 - val_loss: 7.6481\n",
      "Epoch 67/100\n",
      "2263/2264 [============================>.] - ETA: 0s - loss: 6.2179\n",
      "Epoch 67: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2175 - val_loss: 7.6049\n",
      "Epoch 68/100\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 6.1695\n",
      "Epoch 68: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.1695 - val_loss: 7.6298\n",
      "Epoch 69/100\n",
      "2263/2264 [============================>.] - ETA: 0s - loss: 6.2199\n",
      "Epoch 69: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.2195 - val_loss: 7.6391\n",
      "Epoch 70/100\n",
      "2260/2264 [============================>.] - ETA: 0s - loss: 6.1726\n",
      "Epoch 70: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.1705 - val_loss: 7.6594\n",
      "Epoch 71/100\n",
      "2254/2264 [============================>.] - ETA: 0s - loss: 6.1618\n",
      "Epoch 71: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.1612 - val_loss: 8.0300\n",
      "Epoch 72/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 6.1863\n",
      "Epoch 72: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.1882 - val_loss: 7.6307\n",
      "Epoch 73/100\n",
      "2258/2264 [============================>.] - ETA: 0s - loss: 6.1487\n",
      "Epoch 73: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.1445 - val_loss: 7.7580\n",
      "Epoch 74/100\n",
      "2261/2264 [============================>.] - ETA: 0s - loss: 6.1715\n",
      "Epoch 74: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.1732 - val_loss: 7.7749\n",
      "Epoch 75/100\n",
      "2259/2264 [============================>.] - ETA: 0s - loss: 6.1372\n",
      "Epoch 75: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 11s 5ms/step - loss: 6.1379 - val_loss: 7.8750\n",
      "Epoch 76/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 6.1302\n",
      "Epoch 76: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.1273 - val_loss: 7.8167\n",
      "Epoch 77/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 6.1513\n",
      "Epoch 77: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.1504 - val_loss: 7.7516\n",
      "Epoch 78/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 6.1218\n",
      "Epoch 78: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.1235 - val_loss: 7.6674\n",
      "Epoch 79/100\n",
      "2254/2264 [============================>.] - ETA: 0s - loss: 6.1145\n",
      "Epoch 79: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.1150 - val_loss: 7.8241\n",
      "Epoch 80/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 6.0881\n",
      "Epoch 80: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0915 - val_loss: 7.7590\n",
      "Epoch 81/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 6.1072\n",
      "Epoch 81: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.1062 - val_loss: 7.7285\n",
      "Epoch 82/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 6.1227\n",
      "Epoch 82: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.1240 - val_loss: 7.8304\n",
      "Epoch 83/100\n",
      "2254/2264 [============================>.] - ETA: 0s - loss: 6.0752\n",
      "Epoch 83: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0777 - val_loss: 7.7157\n",
      "Epoch 84/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 6.0715\n",
      "Epoch 84: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0701 - val_loss: 7.7278\n",
      "Epoch 85/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 6.1114\n",
      "Epoch 85: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.1104 - val_loss: 7.7964\n",
      "Epoch 86/100\n",
      "2264/2264 [==============================] - ETA: 0s - loss: 6.0611\n",
      "Epoch 86: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0611 - val_loss: 7.7037\n",
      "Epoch 87/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 6.0263\n",
      "Epoch 87: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0281 - val_loss: 8.4132\n",
      "Epoch 88/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 6.0537\n",
      "Epoch 88: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0563 - val_loss: 7.7674\n",
      "Epoch 89/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 6.0979\n",
      "Epoch 89: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0957 - val_loss: 7.7540\n",
      "Epoch 90/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 6.0242\n",
      "Epoch 90: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0262 - val_loss: 7.6898\n",
      "Epoch 91/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 6.0056\n",
      "Epoch 91: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0086 - val_loss: 7.9251\n",
      "Epoch 92/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 6.0648\n",
      "Epoch 92: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0644 - val_loss: 7.7605\n",
      "Epoch 93/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 6.0121\n",
      "Epoch 93: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0123 - val_loss: 7.8223\n",
      "Epoch 94/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 6.0341\n",
      "Epoch 94: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0361 - val_loss: 7.7791\n",
      "Epoch 95/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 5.9813\n",
      "Epoch 95: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 5.9791 - val_loss: 7.7747\n",
      "Epoch 96/100\n",
      "2254/2264 [============================>.] - ETA: 0s - loss: 5.9977\n",
      "Epoch 96: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0002 - val_loss: 7.7629\n",
      "Epoch 97/100\n",
      "2255/2264 [============================>.] - ETA: 0s - loss: 6.0171\n",
      "Epoch 97: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 6.0182 - val_loss: 7.8269\n",
      "Epoch 98/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 5.9884\n",
      "Epoch 98: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 5.9909 - val_loss: 7.8237\n",
      "Epoch 99/100\n",
      "2257/2264 [============================>.] - ETA: 0s - loss: 5.9791\n",
      "Epoch 99: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 5.9771 - val_loss: 7.8285\n",
      "Epoch 100/100\n",
      "2256/2264 [============================>.] - ETA: 0s - loss: 5.9971\n",
      "Epoch 100: val_loss did not improve from 7.56959\n",
      "2264/2264 [==============================] - 10s 5ms/step - loss: 5.9978 - val_loss: 8.4071\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='loss', patience=7)\n",
    "\n",
    "filepath = 'best_model_cnn_checkpoint.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_data=(val_x, val_y),\n",
    "                    callbacks =[es, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8965034-7dc1-4b38-ae75-3d79e044e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 1s 2ms/step - loss: 7.3638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.363758087158203"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model.load_weights(\"best_model_cnn_checkpoint.h5\")\n",
    "test_loss = model.evaluate(test_x, test_y)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6e22a4a-b906-4726-9739-d4d2c320419b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAG2CAYAAAB7zFy5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVS0lEQVR4nO3deXzT9f0H8Nc3SZOmTZue0FJaoFCOlkvlULzQiSCI19Q5ZIgH0zl16hSHUxF+MtzGVFSU6Zioc946LzYUD0Dlvm/kKBToQa+kZ67v5/fHp0mbXpSSNmm+r+fj0UfoN98mn35bmlfen0sRQggQERERhTFdsBtARERE1NEYeIiIiCjsMfAQERFR2GPgISIiorDHwENERERhj4GHiIiIwh4DDxEREYU9Bh4iIiIKeww8REREFPYYeIiIiCjsBT3wzJ49G9nZ2dDpdHjnnXd8xx0OB26//XYkJycjKSkJv/rVr1BVVRXElhIREVFXFfTAk5WVhYULF2LUqFF+x1944QXs2LED+/btw+HDh1FYWIinn346SK0kIiKirizogWfq1KkYN24cIiMj/Y4fOXIEV1xxBRISEhATE4NrrrkGu3fvDlIriYiIqCsLeuBpyS233IJVq1bh5MmTKC8vx4cffohx48a1eL7D4YDdbvd92Gw2nDx5EtwMnoiIiEI28PTt2xdxcXHo3r07EhMTodfrcccdd7R4/vz582G1Wn0fcXFx6NatGyoqKjqx1URERBSKQjbw3H333YiOjobNZkNZWRmSkpLwwAMPtHj+rFmzYLPZfB95eXmd2FoiIiIKZYZgN6Al27dvx/PPP4+YmBgAwG233Ybf/e53LZ5vMplgMpk6q3lERETUhQS9wuNyuVBbWwtVVf3+PWLECLzxxhuorq5GVVUVli5diiFDhgS7uURERNQFBT3wzJgxA2azGatXr8a0adNgNpuxatUq/PWvf0VVVRUyMjKQkZGBiooKPPPMM8FuLhEREXVBigjTaUx2ux1WqxU2mw2xsbHBbg4REREFUciO4ekMQgi43W54PJ5gN4UCQK/Xw2AwQFGUYDeFiIhCjGYDj9PpRH5+Pqqrq4PdFAqgqKgopKamwmg0BrspREQUQjQZeFRVxeHDh6HX69GjRw8YjUZWBbo4IQScTidOnjyJw4cPIysrCzpd0IeoERFRiNBk4HE6nVBVFenp6YiKigp2cyhAzGYzIiIicOTIETidzibblRARkXZp+i0wKwDhhz9TIiJqDl8diIiIKOwx8GhY79698dxzzwW7GURERB1Ok2N4urKxY8di+PDhAQkqGzZsQHR09Jk3ioiIKMQx8IQZIQQ8Hg8MhlP/aJOTkzuhRURERMHHLq0uZPr06Vi5ciUWLlwIRVGgKAqWLl0KRVGwfPlyjBgxAiaTCatXr8bBgwdx9dVXo3v37rBYLBg5ciRWrFjh93iNu7QURcE//vEPXHvttYiKikJWVhY+/fTTTv4uiYiIAo+BpwtZuHAhzjvvPMyYMQP5+fnIz89Heno6AGDmzJmYP38+9uzZg6FDh6KyshITJ07EihUrsGXLFowfPx6TJ0/G0aNHW32OOXPm4MYbb8T27dsxceJE3HzzzSgtLe2Mb4+IiKjDsEurgReXVaDIpnbqc3az6nDPxJg2nWu1WmE0GhEVFYWUlBQAwN69ewEAc+fOxbhx43znJiYmYtiwYb7Pn3rqKXz88cf49NNPMePO38LlaX4LtenTp+OXv/wlAOBPf/oTXnjhBaxfvx4TJkxo1/dHREQUCljhCRMjRozw+7yqqgozZ85EdnY24uLiYLFYsHfvXhw9ehRVtSqK7c0Hu6FDh/r+HR0djZiYGBQVFXVo24mIiDoaKzwNtLXSEooaz7Z6+OGHsXz5cixYsAD9+vWD2WzG9ddfD6fTCbSyi0ZERITf54qiQFU7t+pFREQUaAw8XYzRaGzT7u6rV6/G9OnTce211wIAKisrkZubC6DVvENERBSW2KXVxfTu3Rvr1q1Dbm4uiouLW6y+9OvXDx999BG2bt2Kbdu2YcqUKb5zuVEqERFpDQNPF/PQQw9Br9cjOzsbycnJLc66evbZZxEfH48xY8Zg8uTJGD9+PM4++2wA9RWe5octExERhR9FCBGWr3t2ux1WqxU2mw2xsbF+99XW1uLw4cPo06ePJnfUtlWrKKtUkRKvR2REeFV7tP6zJSKi5rHCo0G+iBOeWZeIiKgJBh4N8g7hYdwhIiKtYODRMBZ4iIhIKxh4NIiTtIiISGsYeDTIN0uLFR4iItIIBh4NY94hIiKtYODRIIUL8RARkcYw8GgQ8w4REWkNA48WeaelM/EQEZFGMPBoTO/evfHi8wt9nyuKgv/85z8tnp+bmwtFUbB169Yzet5APQ4REVF7cLd0DWq48GB+fj7i4+MD+vjTp09HeXm5X5BKT09Hfn4+kpKSAvpcREREbcHAo2FCACkpKZ3yXHq9vtOei4iIqDF2aXUhf//735GWlgZVVf2OX3XVVbjllltw8OBBXH311ejevTssFgtGjhyJFStWtPKIokmX1vr163HWWWchMjISI0aMwJYtW/y+wuPx4Pbbb0efPn1gNpsxYMAALFxY30X25JNP4vXXX8cnn3wCRVGgKAq+++67Zru0Vq5ciVGjRsFkMiE1NRV/+MMf4Ha7ffePHTsW9913H2bOnImEhASkpKTgySefbM+lIyIijWPg6UJuuOEGFBcX49tvv/UdKysrw/Lly3HzzTejsrISEydOxIoVK7BlyxaMHz8ekydPxtGjR/0ep6WFB6uqqnDllVdiwIAB2LRpE5588kk89NBDfueoqoqePXvivffew+7du/HEE0/g0UcfxXvvvQcAeOihh3DjjTdiwoQJyM/PR35+PsaMGdPkezl+/DgmTpyIkSNHYtu2bXj55ZexZMkSPPXUU37nvf7664iOjsa6devwl7/8BXPnzsVXX33VzitIRERaxS6thl6YDZzM79znTE4F7p3TplMTEhIwYcIE/Pvf/8bPfvYzAMD777+PhIQE/OxnP4Ner8ewYcN85z/11FP4+OOP8emnn+Kee+6pf6AWNg9966234PF48M9//hNRUVHIycnBsWPH8Jvf/MZ3TkREBObMqW9vnz598OOPP+K9997DjTfeCIvFArPZDIfD0WoX1ksvvYT09HS8+OKLUBQFAwcOxIkTJ/DII4/giSeegE4ns/jQoUMxe/ZsAEBWVhZefPFFfP311xg3blybrhkRERHACk+Xc/PNN+PDDz+Ew+EAIEPKTTfdBL1ej6qqKsycORPZ2dmIi4uDxWLB3r17m1R4vBpXePbs2YNhw4YhKirKd+y8885r8nWLFy/GiBEjkJycDIvFgldffbXF52jJnj17cN5550FpsLHX+eefj8rKShw7dsx3bOjQoX5fl5qaiqKiotN6LiIiIlZ4GmpjpSWYJk+eDFVV8cUXX2DkyJFYvXo1nnnmGQDAww8/jOXLl2PBggXo168fzGYzrr/+ejidTr/HaGnzUNGGhXnee+89PPDAA/jb3/6G8847DzExMfjrX/+KdevWndb3IYTwCzsNn7/h8YiIiEZtV5qMYSIiIjoVBp4uxmw247rrrsNbb72FAwcOoH///jjnnHMAAKtXr8b06dNx7bXXAgAqKyuRm5vb5DFaGsOTnZ2NN998EzU1NTCbzQCAtWvX+p2zevVqjBkzBnfffbfv2MGDB/3OMRqN8Hg8rX4f2dnZ+PDDD/2Cz48//oiYmBikpaW1+rVERESni11aXdDNN9+ML774Av/85z8xdepU3/F+/frho48+wtatW7Ft2zZMmTKl1WpI43rOlClToNPpcPvtt2P37t1YtmwZFixY4HdOv379sHHjRixfvhz79+/H448/jg0bNvid07t3b2zfvh379u1DcXExXC5Xk+e+++67kZeXh3vvvRd79+7FJ598gtmzZ+PBBx/0jd8hIiIKFL6ydEGXXnopEhISsG/fPkyZMsV3/Nlnn0V8fDzGjBmDyZMnY/z48Tj77LNbfqBGicdiseCzzz7D7t27cdZZZ+GPf/wj/vznP/udc9ddd+G6667DL37xC4wePRolJSV+1R4AmDFjBgYMGOAb5/PDDz80eeq0tDQsW7YM69evx7Bhw3DXXXfh9ttvx2OPPXb6F4SIiOgUFNGWgRtdkN1uh9Vqhc1mQ2xsrN99tbW1OHz4MPr06YPIyMggtTC4covciDIp6GbVB7spAcWfLRERNYcVHo1SFG4eSkRE2sHAo1EtTNQiIiIKSww8GsUKDxERaQkDj4Yx7xARkVYEPfDMnj0b2dnZ0Ol0eOedd/zuW7t2Lc4991xYLBbf/k0UGArattAgERFROAh64MnKysLChQsxatQov+P5+fn4+c9/jscffxzl5eXYtm2bb4G9QNHyC35Lqy13dVr+mRIRUcuCHnimTp2KcePGNZlC/Oyzz2L69OmYNGkSDAYDEhMT0bdv34A8p3e7gurq6oA8XlcVjtnA+zNtvCUFERFpW8huLbFhwwacf/75yMnJQWlpKS677DI8//zziI+Pb/Z8h8Ph21ATkOvwtESv1yMuLs63CWVUVFSTfZ3CncflhhBAbW3I/gqcFiEEqqurUVRUhLi4OOj14bW+EBERnZmQfbU7fvw43nrrLSxfvhxpaWm44447cP/99+P1119v9vz58+djzpy2b/6ZkpICAJrdedtWrUJVgeryoBf5AiouLs73syUiIvIK2cBjNpsxdepU9O/fHwDw+OOP4+KLL27x/FmzZuHBBx/0fW6325Gent7i+YqiIDU1Fd26dWt2r6dw98qXlSir8uCRa63BbkrAREREsLJDRETNCtnAM3jwYL/PTzUY1WQywWQynfbz6PV6Tb5IOlUnyms83H6BiIg0Iej9GS6XC7W1tVBV1e/f06dPx2uvvYZDhw6hpqYG8+fPx6RJk4Ld3LCh1wNuTxiOWiYiImpG0APPjBkzYDabsXr1akybNg1msxmrVq3CuHHj8MADD+D8889Hz549oaoqnn322WA3N2zodQrcarBbQURE1Dk0uVs6AS/9twJbc1145TcJwW4KERFRhwt6hYeCw6BXIASgqmGZd4mIiPww8GiUvu4nz24tIiLSAgYejfIGHg8DDxERaQADj0YZ9HJlac7UIiIiLWDg0ShWeIiISEsYeDTKoJMVHg8HLRMRkQYw8GiUd3Fptye47SAiIuoMDDwaVT9LixUeIiIKfww8GlXfpRXkhhAREXUCBh6N8nZpedilRUREGsDAo1EctExERFrCwKNRvkHL7NIiIiINYODRKN+gZS48SEREGsDAo1EctExERFrCwKNRHLRMRERawsCjUd4KD9fhISIiLWDg0SjupUVERFrCwKNRBm4tQUREGsLAo1F6rsNDREQawsCjUezSIiIiLWHg0SiDvm7QMtfhISIiDWDg0aj63dKD2w4iIqLOwMCjUQZ2aRERkYYw8GiUvq5Ly8MuLSIi0gAGHo1ilxYREWkJA49GGTgtnYiINISBR6MM3EuLiIg0hIFHo7gODxERaQkDj0bpuXkoERFpCAOPRvkGLbNLi4iINICBR6Pqu7RY4SEiovDHwKNRiqLAoOMYHiIi0gYGHg3T69ilRURE2sDAo2F6vcIuLSIi0gQGHg0z6LjSMhERaQMDj4bpdQr30iIiIk1g4NEwg56DlomISBsYeDRMzy4tIiLSCAYeDdPrFLjZpUVERBrAwKNh7NIiIiKtYODRMIOO09KJiEgbGHg0TM8KDxERaQQDj4ZxpWUiItKKoAee2bNnIzs7GzqdDu+8806T+91uN4YMGYKBAwcGoXXhjV1aRESkFUEPPFlZWVi4cCFGjRrV7P0vvvgirFZrJ7dKG9ilRUREWhH0wDN16lSMGzcOkZGRTe4rLCzEK6+8glmzZp3ycRwOB+x2u98HtU6vU+BRAVWwykNEROEt6IGnNY888ggeffRRREdHn/Lc+fPnw2q1+j7S09M7oYVdm77up88qDxERhbuQDTxr1qzB/v37cfPNN7fp/FmzZsFms/k+8vLyOriFXZ9BL28ZeIiIKNwZgt2A5qiqivvuuw8vvfQSFEVp09eYTCaYTKYObll4MejktfV4BBDRtutMRETUFYVk4LHb7di8eTMmT54MAHA6nbDb7UhJScGhQ4cQFRUV5BaGB2+XFvfTIiKicBf0wONyueDxeKCqKlwuF2praxETE4Pjx4/7zvnxxx/xyCOPYPXq1TCbzUFsbXjRe7u0uJ8WERGFuaCP4ZkxYwbMZjNWr16NadOm+f6dkpLi+0hISIBer0dKSkqbu7jo1LxdWqzwEBFRuFOECM85yXa7HVarFTabDbGxscFuTkj6z7pqfLGpFnNvsiI1QR/s5hAREXWYoFd4KHgM+rpBy1xtmYiIwhwDj4Zx0DIREWkFA4+G+QIPBy0TEVGYY+DRsPourSA3hIiIqIMx8GiYgVtLEBGRRjDwaJhex0HLRESkDQw8GuZdeNDtCW47iIiIOhoDj4bVLzzICg8REYU3Bh4N05/pGJ5KO1BZEbD2EBERdRQGHg0z+PbSaucDLJoL/H1ewNpDRETUUYK+eSgFj/5Mu7RKiwAdt6QgIqLQx8CjYWfcpeV2AXAFqjlEREQdhoFHwwy+WVrtrPC4XIDgIj5ERBT6GHg0rH4dnnY+gNslP4QAFCVwDSMiIgowDlrWsDNeadntAlS1rmuLiIgodDHwaJi+bi+tdnVpqR4ZdgDA6Qhgq4iIiAKPgUfDfLult6fC42pQ1XHUBqQ9REREHYWBR8Pqu7TaUeFp2I3lZOAhIqLQxsCjYYa6Lq12LTzoF3jYpUVERKGNgUfDzmgdHje7tIiIqOtg4NEw36Dl9nRpcQwPERF1IQw8GuYdw+NmlxYREYU5Bh4NY5cWERFpBQOPhimKAr2unbO0XJylRUREXQcDj8bpdQHo0nKwS4uIiEIbA4/G6XUK1+EhIqKwx8CjcQY9x/AQEVH4Y+DRONmldaZjeNilRUREoY2BR+Nkl1Y7vpAVHiIi6kIYeDTOoA/EOjwMPEREFNoYeDTOEJBBy+zSIiKi0MbAo3FyHZ52fCG3liAioi6EgUfj9IHo0mLgISKiEMfAo3F6ndK+zUPZpUVERF0IA4/GGc60S8tkZoWHiIhCHgOPxhn0CjztWYfHW+GJjuEsLSIiCnkMPBrX7kHLfoGHXVpERBTaGHg0Tq8D3CogxGlWedxOeRsdI7u0TvfriYiIOhEDj8YZ9AqAdlR5vGN4oi2AqvoPYiYiIgoxDDwap6/7DTjtwOMNOFEWectuLSIiCmEMPBpn0HkrPKfbpeUCDBGAKVJ+zplaREQUwhh4NE6vl7envfigN/AY6wIPZ2oREVEIC3rgmT17NrKzs6HT6fDOO+/4ji9duhTDhw9HTEwMMjMzsXjx4iC2Mny1u0vL1ajCwy4tIiIKYUEPPFlZWVi4cCFGjRrld9zhcGDx4sUoKyvDZ599htmzZ2PVqlVBamX48nZpnfZqy24XEBEBGE3yc3ZpERFRCAt64Jk6dSrGjRuHyMhIv+N33nknzj33XBgMBuTk5OCyyy7Dhg0bgtTK8OXt0vK0t0uLFR4iIuoCgh542sLj8WD9+vXIyclp8RyHwwG73e73Qaem56BlIiLSgC4ReB577DGkpaVh/PjxLZ4zf/58WK1W30d6enontrDrMtT9BrjbO4aHXVpERNQFhHzgWbx4MT766CN88MEHUBSlxfNmzZoFm83m+8jLy+vEVnZdhjOZpRXRcJYWu7SIiCh0GYLdgNa8++67mDdvHlavXo2kpKRWzzWZTDCZTJ3UsvDR7i6txrO0WOEhIqIQFvTA43K54PF4oKoqXC4XamtrYTQasWLFCtx7771YsWIFevfuHexmhq0zWmm5YZcW1+EhIqIQFvQurRkzZsBsNmP16tWYNm0azGYzVq1ahfnz56OsrAxjxoyBxWKBxWLBXXfdFezmhp36vbTOcNAyu7SIiCiEBb3Cs3TpUixdurTJ8bFjx3Z6W7TIW+E5rTE8QtSP4WGXFhERdQFBr/BQcBna06Xl3TiUs7SIiKiLYODROH17Vlr2Czzs0iIiotDHwKNx7VppuWHgMRgAvYGDlomIKKQx8Ghcu/bSctUFnogIeWs0sUuLiIhCGgOPxvkqPO0dwwPIgcvs0iIiohDGwKNxvkHL7e3SAmTgYYWHiIhCGAOPxp3xoGWAXVpERBTyGHg0rl2DlpuM4WGXFhERhbaABZ6ysrJAPRR1onYNWm52DA8rPEREFLraFXjefPNN3HbbbdixYwcKCwsxdOhQJCUloVevXti5c2eg20gdyHCm09KB+i4tcZrbUxAREXWSdgWel19+Gf/617+Qnp6Ov//979i5cyeEEMjLy8Njjz0W6DZSB2rX5qGuZio8qgp43AFtGxERUaC0K/Ds27cPGRkZiIuLw48//oikpCSsWrUKsbGxWLduXaDbSB3ojAYtN1yHB+DAZSIiClntCjxVVVWIi4sDAOzduxfnnHMOLrjgAvTr149jeboYb5fWaW0e2twYHoCBh4iIQla7Ak+3bt2we/duzJ07F0ePHsWQIUMAAKWlpUhMTAxoA6ljeSs8njOals79tIiIKLS1K/BMmjQJtbW1mDNnDhRFwVVXXYXS0lIcO3YM2dnZgW4jdaB27Zbe3NYSAGdqERFRyDK054sWLFgAs9mMAwcOYPLkybjggguwYcMG/OIXv8CVV14Z6DZSBzLo5cDlGucZTksH2KVFREQhq12BJzo6Gs8884zfsZEjR+LNN98MSKOo8yiKAmuUDuVVp1HiaSnwsEuLiIhCVLu6tDZu3Ig33ngDR48ehdPpxL333othw4Zh2rRpsNlsgW4jdbDYKAW26jMIPJylRUREIa5dFZ7HHnsMX331FQ4dOoR//vOfWLRoEQBg586dsFgseOmllwLaSOpY1igd8oo9UIWATlFO/QWNx/CwS4uIiEJcuyo827ZtQ2pqKnr16oUVK1bAbDZj7ty5MBgMWLZsWaDbSB3MGqWDRwWqats4joeztIiIqItpV+ApLS1FSkoKAGDXrl0YMWIEHnvsMeTk5KCwsDCgDaSOZ42Wvwa2to7jYZcWERF1Me0KPHFxccjNzcWqVatw8OBB5OTkAACqq6thsVgC2kDqeNYo2Y1lqz7NCk+EUd76Bi0z8BARUWhqV+AZPXo0SktLcckll8Dj8WDs2LFwOp3Iy8tDZmZmoNtIHcwaVVfhaevA5eb20gLYpUVERCGr3evwHDt2zLcOz/XXX49Vq1YhISEBV1xxRaDbSB3stAMP99IiIqIupl2Bp3///ti8ebPfsbFjxyIvLy8gjaLO5evSOp0xPDodoKvbiIuztIiIKMS1K/AAgNPpxNtvv42NGzcCkAsP3nTTTTAajQFrHHWOWF+Fp41jeFyu+u4sgLO0iIgo5LUr8JSVlWHs2LHYuXOn3/FnnnkG3333nW8ndeoaDHoFlsjTWHzQ3SjwGAyAXs9By0REFLLaNWj5sccew44dOyCEgNlsRmRkJIQQ2LFjBx5//PFAt5E6gTVKdxqBx1k/fsfLGMkuLSIiClntCjyfffYZIiIi8PHHH6OyshJVVVX46KOPoNfr8cknnwS6jRRoB/cAyz8EVI/vkDVKOb0xPIZGgccUyS4tIiIKWe0KPIWFhejfvz+uvvpq37FrrrkGAwYM4MKDXcGGlcD7rwKlJ32HrNE6ONxArasN43gaj+EB5EwtVniIiChEtSvwJCQk4ODBg9i2bZvv2NatW3HgwAEkJCQErHHUQZJT5e3JfN8h39T0tlR5WqrwMPAQEVGIalfgGTduHGprazFixAgMHjwYQ4YMwciRI+F0OnH55ZcHuo0UaN7AU9RM4GnLOB63q/kxPOzSIiKiENWuwDNv3jykpqbC4/Fg9+7d2LVrFzweD1JSUjBv3rxAt5ECrVtzFZ7m1+LZcMCB/Sdc/l/fXIXHaOIsLSIiClntmpaenp6OrVu3YtGiRdiwYQMAYNSoUbj77ruRnJwc0AZSB0jsDiiKf+CJbroWj9sj8M8VVUi26jH3l9b6r3e5AEOj9Za8XVpCyMcmIiIKIW0OPHPnzm1yTKfTYfTo0b7PX375ZQDAE088EYCmUYeJMALxyc2P4WnQpXWi1AO3CuSXeWCvVn0LFLY4hkdVAY+76X1ERERB1ubA8+STT0Jp4zt3Bp4uoFsqcOQnX0WmucBztLh+2vq+4y6MzKrbM8vV3BieBvtpMfAQEVGIaXPgycjIaHPgoS4gKQXYuw2otAMxVkQaFZgMjQOP2/fvvcfdMvB4PIBQm6/wADLwRMd0xndARETUZm0OPLm5uR3YDOp0DQcux8jxOdZoHWxV9WN48k56EGVSYDYq2Hu8buCyd6f0JoOWuZ8WERGFrnbN0qIwkNxD3jYax+Ot8KhCIK/EjfREPQamGVBkU1Fa4ZHdWUDLXVqcqUVERCGIgUermll8MDZKh8paAbdHoMimwuEC0pP1GJgmw83e4265jxbQepcWERFRiGHg0apuTRcfjKtbi8deI5B3Uo7fyUgyYEBd4Nl3wtVKl5a3wsMuLSIiCj0MPFoVZZGDi5tbi6dK9c3QykjSI96iQ/c4HfYec0O4Wgg8rPAQEVEIY+DRsuTUFtfiOVrsRoQeSInXAwAGpkWgtFJFWXldBafxGB5f4Knp8GYTERGdrqAHntmzZyM7Oxs6nQ7vvPOO331PP/00kpOTkZCQgJkzZ0KINuzkTW3XLRUoL/F1Q8V6t5eoVpFX7EFaoh56nTzmHcdzJL8u0DSu8HinoldVdny7iYiITlPQA09WVhYWLlyIUaNG+R1ftmwZXn75Zaxbtw67du3C559/jtdeey1IrQxTSXXjeIoLAABxdRWeIyc9qKgRyEiqX7VgQJr8d15BXZdV48Bjqdt6otLWce0lIiJqp6AHnqlTp2LcuHGIjIz0O/7mm2/i7rvvRmZmJlJTU/HQQw/hX//6V5BaGaYaDVz2juHZeUSO00lP0vtOjTHrkJagx4miFgJPTKy8rWDgISKi0BP0wNOS3bt3Y8iQIb7Phw0bhl27drV4vsPhgN1u9/ugU2g0NT06UoFeB5TV7Ziekey/LuXANAMcNXXT0huP4YmOkZuGMvAQEVEICtnAU1lZidjYWN/nsbGxqKxseXzI/PnzYbVafR/p6emd0cyurVHg0SkKYsxyzI6iAGkJer/Th/UxIkLUbTfRuMKj0wPRsXKrCiIiohATsoHHYrH4VWnsdjssFkuL58+aNQs2m833kZeX1xnN7NriEmVwKWo6UyslTg9ThP/eaQPTDOgZK6s/Nqd/GAIAWGJZ4SEiopAUsoEnOzsbO3bs8H2+bds25OTktHi+yWRCbGys3wedgk5XNzX9hO9QgllFenUuMpKaBhpFUTCijwxBG3KbmTEXY+WgZSIiCklBDzwulwu1tbVQVdXv31OnTsXLL7+Mw4cPo6CgAM888wymTp0a7OaGn+RUoKQIUOVCgxO2vown9j6KHBxp9vQeFlnh2ZkPFJZ7/O+0xAKVFYCqNvOVREREwRP0wDNjxgyYzWasXr0a06ZNg9lsxqpVqzBp0iTceeedGDlyJAYNGoSJEyfi1ltvDXZzw09yitwuoqwEWLMCmbmrAAB9i7c1f37d1hIuRODzjY0WGYyxAkIFqio6ssVERESnLeiBZ+nSpRBC+H2MHTsWgByXU1xcjLKyMvzlL3+BoiitPxidPu/A5V2bgH8tghqbAI/BiOTjrQeenikmrPvJifzSBlWeGO9aPBy4TEREoSXogYeCzLsWz79fApy10M2YCf2AwVAO7G5+I9C6vbQuHBoDIYDPNzWo8ngXH+TAZSIiCjEMPFqX3EPeul3AhBuAQcOBQWfJzw80s+6Rt8LTPRK9kvXYc8xVf18MV1smIqLQxMCjdUndAZMZ6N0fuHqaPJZ9lrzdvbXp+e763dLTEvWoqBGoqq0bpGzhastERBSaDKc+hcJahBF44kXAmgAY6n4dembK8LJnS9PzGwSelDg5dT2/zIN+qbr6Cg8DDxERhRhWeAjongZEmus/1+mAgcOAowfkNPOG6sbwICICqfHewFNX4YmJk7cctExERCGGgYeaN+gsQAhgX6PZWg0qPN7AU+Bdj8fXpVXeOW0kIiJqIwYeap5vHE+jbi1v4IkwIilWB4NOdmkBAIwmwBTJCg8REYUcjuGh5iWnygHNjcfxeAOP3gC9oqBbnB4FZQ3W4uF+WkREFIJY4aGWDToLKDoBlBTWH3O55IajdYtApsbrUGxX4XTX7a0VY2WFh4iIQg4DD7VsUF231p6t9cfcLiAiwvdparweAkCRbxwPNxAlIqLQw8BDLRs0TN42HMfjrqvw1Gk4NR2ArPA4HYCjtrNaSUREdEoMPNSymDigWw/g2KH6Y40CT/3U9AYVHoBVHiIiCikMPNS6lHSg8ATgqQs0Lv/A0z1ODwVAQbl3LR6utkxERKGHgYdal9oT8LiB4gL5eaMxPKYIBQkxumYqPBy4TEREoYOBh1qXki5v8/PkbaMuLUB2axWUe6CqosH2EuWd10YiIqJTYOCh1qX0lLeFx+RtM4EnJV4HtwcorlDrKzzs0iIiohDCwEOta1zhcTVf4QEgFyCMYZcWERGFHgYeal2MVa6eXNCgSyuiUYWn4dR0VniIiCgEMfDQqaX0BApa7tLym5oeFS13W2eFh4iIQggDD51aSk8ZYCpszQaeGLMOlkhFTk3X6YDoWA5aJiKikMLAQ6fmHcdz7LC8bRR4AFnlyS/zQIi6mVrs0iIiohDCwEOn5g08eQflbUTTwJMSr0e1Q6CiRnADUSIiCjkMPHRqqd7A463wGJue0nAcjyUWqKqoX52ZiIgoyBh46NSSUgC9odUurYwkGXh2HXXJPbgAGXqIiIhCAAMPnZpeLzcRzT8qP28m8GT1MKCbVYfVexzwRMXIgxy4TEREIYKBh9ompaecoQU0O4ZHpyi4ZHAkKmsFjtRY5EGO4yEiohDBwENt4x3HAzRb4QGAMQONMBmArcVmeYAztYiIKEQw8FDbpJw68ESZdDhvoAm5NdHyAAMPERGFCAYeahvvJqJAs11aXpcOjkSFIVZ+UsnAQ0REoYGBh9qmYeBpocIDAKkJeqSmxwMAaksZeIiIKDQw8FDbRFkAqwwyrQUeADj3nGQAwMkTZW177L3bgOqqM2kdERFRqxh4qO2843hOEXgGZ0ahVm9GdXEZnG7R+mOeOAoseAT4+LUANZKIiKgpBh5qO2+3VitjeABAp1OgRsciylmBtfsdrT/m3q3ydssaQFXPvI1ERETNYOChtkvNkLfGyFOeGpkYjwRXCb7ZXAlVtFLl2bdd3paXAEcPBKCRRERETTHwUNtdcDlw4wxgwNBTnqo761xEuyvR6/BqbM91NX+SEMC+HYCpbt2erWsD2FgiohDT2ps/6nAMPNR2kVHA5T8HDIZTnzt2MkRkFK4o/BRfbalu/pwTR+TU9QvHyw1Ht64JbHuJKDy9/BTwxsJgt+L0vfgk8OyjDD5BwsBDHSMqGsqlVyGlNh+WPWtxqNDd9Jz9O+TtwOHA0FFyc9Ligk5tJhF1MU4HsOVHYP3KrjXuz+MB9m4HXC5AUYLdGk1i4KGOc9k1UCNMmFjwH3y5pabp/fu2y//4/QcDw8+Tx7at69w2ElHXcjxXBp3aaqDgWLBb03bHDwOOGqBfTrBbolkMPNRxYuOgu3A8etXkonbrRhTZPPX3ecfvpGfKNX6yz5bT3dmtRUStOXqw/t+5+4PXjtP10y552y87uO3QMAYe6ljjr4fQ6XFFwSdY+HkFCsvrQk9+HlBRDvSvGwAdaQYGDZfdXNWVwWotEYW6vEP1/+5KgefAblnR7jso2C3RLAYe6liJ3aCc9zMMqNyLuOO7MP9DO/afcNVPR28442v4ebKfe+fG4LSViELf0QNykoMlFji8L9itaRshgAO7gB69gOiYYLdGsxh4qONdcSNgiMDvCv8Ok8OOZz+tQMnGLfLdTtbg+vOGjZa3odKtJQTw/ZeArY1bZBBRx1I9cnJDel+gV5as9rhbWPYilJQWAWXFHL8TZAw81PFSegI3/xZGWxGerPw7YiIFDAd3orZ7b8DS4N1OXCLQuz+wYwPgcgatuT4/7QKWPsNtL4hCRdEJOUsrIxPoM0CGnWO5wW7VqR3YLW85fieoQj7wbN68GWPGjEFsbCwyMzPx2mt88emSLpwAXDgB5v2bMafqFVjdNqxXBqC8qtG00tGXADXVwOr/BaedDe3eJG83/xi4d5FCAIvmAu+/GpjHI9IS74DljH7yzRHQNcbx+AYss8ITTCEfeKZNm4ZJkyahvLwcH3zwAe677z7s398FfsGpqSl3A72yYN6yEgCwwzwIr35VCY/aYBGui64AYuKA/77X/iqPywms/QbYs+XM2ru77uurK4Hdm8/ssbwO75driHz7eWhUsYi6kqN1A5bTM4E+3sDTBcbxHNglK9hJ3YPdEk0L+cBz5MgRTJkyBTqdDmeffTYGDRqEffu6wC84NRVhBH7zRzloT1GQOnIY9p9w4z/rGqzRY4oEJtwg+7sbV3kcta2/mys9CXy0FHj4V8A//gL8bRbwnzfatzhZZYUMJ72y5OcbVp3+YzRn1TJ563QAe7YG5jGJGtq4CljwB/n/JdzkHZB/R7r3BKwJQHyS/H8ayqor5dpB/bK54GCQhXzgueeee/Dmm2/C7XZj/fr1yMvLw+jRo5uc53A4YLfb/T4oBCWlAL+fD/x6Fq66tDv6dNfjf1tqsS23QbVj7KSmVZ7qKuCvM4Gn7gN++Krp4675GvjDLcCydwBzFHD97TKsfP5v4IXZpz/Vfe9WQKiy4tQ7S+7mfqYVmZoqYMNKICFZfr6Ne4dRB/j8bfn7u319sFsSWELILq2efQC9Xh7rMwA4cTS0w92hvbLt7M4KupAPPBMmTMCSJUsQGRmJMWPGYN68eejWrVuT8+bPnw+r1er7SE9PD0JrqU0y+gEjL4JBr+DOyy2IMil4/dsqVNTUVWJMkcAVDao8NVXAc3+U1R2jCXjrRbmOj9fhfcDrz8l3fPfNAeYtkVWiRxYAYy6Tg6Cfuu/0tq3wdmFlnw2MvFiu6nqm0+XXfyf/MF85BeieJleV5p46FEh5h+QsJkCG63BiKwUqbLI7y6t3f/nG5MiBtj2Gqnb+rK6fdspbBp6gC+nAU1JSgsmTJ+O5556Dw+HA1q1b8cQTT2DduqbbD8yaNQs2m833kZeX18wjUqhJjNHj5ouiUFEj8MZ3VRDeAHBxXZVn2bvAwsflu6QrbgTunyf3olk8T3YL2cqAl/5Plop/OxsYOhrQ1f1aG03Arb+XY4dO5gOL/q9t7wSFAHZtArr1AJJTgBEXyeNn+gKy6n9yZ/hRY4Fh5wLlJW3/Q03UFmu/kbfWeBn0a1vYuLcrajhg2et0x/G8Mh+YdStQUhjYtrXmwG75Jq5hUKOgCOnAc+jQIVitVlx77bXQ6/UYPHgwxo4di1Wrmo6nMJlMiI2N9fugrmFUlgkj+xmx9bALa/bVdRt5qzzlJfIPxvifA9fdKvfduvpXsk/83y/J4FNWDEy7T3Y9NaYowKVXAVdNBfIOyh2WT1VVKToBlBTJ6g4AJHaTq6NuW9f+0vmRn+TH6LFyVenh58rj7NaiQFE9wLpv5cDYK6fILtjT2Ztuyxrgb38AvvkUqG1m77tgy2swYNnLO8auLTO1dmwANq6Wfy9enNs53WBut6xA9xlY3w1HQRPSgad///6oqKjAZ599BiEE9u7di2+++QZDhgwJdtMowG6+KApx0QreXl2Fkoq67ScungQMHAZc+Uvg+jvqB/xNvFFuQ/H9clkuvuwa4LzLWn+CSb8EzhojXxC++qj1c73dWTln1x8bebH8A7mjneMiVtUNwL7oCnnbN1sO3u6owPPTTjnuibRj7zb5BuHcS4GzLwAUnXyBPxW3C3hnMbBojhxI/++XgIenAu++0rZKiMcDrFkBFJ449bm7NwOfvCmrs6fr6AH5N6Bnn/pjURa5ztepBi673cB7r8qq76VXyTc/r/3N/83P8Vxg0/dAVcXptSt3P/Cf1+UEic//Dfz3fTmW8D9vyO53pwPIYndWKDAEuwGtsVqtePfdd/HII49gypQpiI+Pxz333IMJEyYEu2kUYNGROtxySTQWfl6Jf35dhd9fFQOdKRJ46M9NT9bpgTtmAn+6H0hJl2HoVHQ64LbfA/PygPeXAKkZwOARzc+a2LVZnj9gWP2xERcC7/5dztbydnG1VW2NDFre1WEB+W5vyEjZBVF6sn4gcyBs+h54+Sm5ivXDf6nv4usstTXAio+BkWOB7j0697lDTVWFDNglRYA5GoiKljOLzrtMvvgG0pq67qxzfya7tAYMlVWNmir53I2pHjkW7rVn5It2Vg5wywPAvm3Aik9ku7/5BBh9KTDxFzJYNCaEDEgrv5ABa/RYYOJNQI+Mps/16b+AL96p7zK+50kgNq7576XwOLD8AznW7bJr5f+XvENydpYp0v/c3v3l/6NKu9xuojmrlgH5R4HJN8tqr61UhsGe78iq8f/erx/krdcDA4cDZ58vn99okjPDTJFAjBWIjJLn7d8hg82uUyxZoSjybw0FXUgHHgAYP348xo8fH+xmUCcYnGHE2MEmfLfTgc821uDqUVEtn2xNkIOT9Ya2T/U0RwP3PAHM+50cF5ScKkPH0FHAoLPkHzq3W75T7jNQvjh5xSXKALFtHXCyQI7taQtVle/0aquBiyb4t3X4ufIP9bZ1wCVXtu3xTsVeDrz5gvz3TzuBVf+Vs946i+oB/vFnYOtaWdWa9Yx8gdcat1u+yH76L/lC3Nj29cDdTwSum8NRC2z+Qc5a8gaTkRfK2Vrb1smqDwDs3ymrECfz5XYHnrpq6sRfAFdPk+1J6QlcNFFWY754B/jxKzkLcuRFwLXT/X/3v/pIhp2swYAhQv4+r/sWyBkBDBwqB+rGJ8pQtXebDPxZOcCK/wB/+h1w31y5v5TXyQLZvjUr6peT2PwDcPNvZVfzqIubfu/ewDP3t/KNgzVBHrt4oqwAVVXIqlJ8kpzMoChybF/hcVmZAeSxcy6QIXH7elnp2rWp+WsdYZR/G2xlMuSNGgv87Gr598XjlmMMdTrAaAQiTPJc7p8VEhQhwnOaiN1uh9Vqhc1m43ieLsTlFvjzx3YcOenBvRMtGNrbGPgnOXpQBoHt6+UffUAOUJ50E5DYHVjwiHwXeNVU/6/bvRl45lEgcyAwcwFgOMX7BUct8M8FsuKSORD4/dP+705rqoD7fyG75+5/qu3tVz0yUKz7Vq5Mffb58rgQsrKz+QfglvuBz96S3Vpz/x7YClJrPlgi3y337i+rBmm9gZl/bdsf/O3rZRXtrPOB62/r8KZ2mO3rgfdeAQqOyRfZa6fLF9OaKvnzWPaOfIEecxkw/cHAVODWfQu8+mc5QP/Sq+SxinLgwSnAsFGymrJ9vfz9EEKGmqTu8vf9rDGy67gl+3cCX7wtA4DRBEyeCoy7VnbvvvR/QGo68IdnZLg4uEeGpJ0bmq5/dcmVwI2/loHh++XAm8/Lx8s5RwZ1W6mcSenxyOBx5RRg+zrgq4/lNVJV4Oe3y7F9DZWXAG8tAooL5b8ryuVxcxRwyWT52N8vB25/GDjvZ/VfV1wA/H0+kNEXuPznsprjVV0pKzcV5XIslMspK5f2cvlRWS4HT4+/gVXMLoSBh0JOsd2D/3tfvit+7PpYJFs7aLCfEMCJI3K6+DefyRckQ4Qc0zDrGTnOprH3XwWWfyjL9tdNb/mxy0uAF58Ecn+SXWC3/b75LoxnHpWl8T/8Tb4ztcTKF4SGXE653UZNleyi+PoT+Q7d6+KJ8oVky49ywcURFwF3PSrPXfi4nLl275PyXezJAtlNkd5X/vE/VXVMiKbnVFfJysWPX8mwdsUv5IDxH76U7+QzB8qutBWfAB8uke/+H5gnH+vQXnlNErsBA4bI77mqQgadH1fUP0fDF+6Gz1tpa9DFYD516GwrIeTK2t99LgNldN1u3N17yC6ixt0ozcnPk+Nedm6QbbziRvlC2vhr3W7gpbkygIy7DrhxxpktSCeE/Dnv2QIseEvObvT62yxZ6bv5t8C/XpQh4IF59V2rp2PPFlk9LDohg+zJfPm9PbqwacWztkYG3gO75TT5ERc07Qres0UGjko7YLHK7q3kFNmFNWh4/Xl7t8k3DqUnZRd3a+EMkP9f1q8E/vuuDJ2ArHzNerbzu3cppDDwUEjaccSJF76oRM8kPe6/MgYCsvpjNiqIjuyAP1rVlXJ2ypcfyT/iT7/efHeD2wXMf1AOoHxwvvzD7KiVU9Z3bJBBp6wEsJXId6pX/hK46lct/6H95lM5BqIhnU6+ACo6+WLmcfvfb7ECYyfKys77/5Dl9x4ZQHmpDGxzFsuxBoB817/uW+CGGUD+Edk14e3GyD5bzm5LSpEvEhtXyxf8ohOyLO9yynYMGAoMP0/uZr9vu3xOexmQ0K2+QtZ/iHx3b40H/vi8vBVCBoAVH8tKh72s/rm9UjOA6grZPTB4JPDzW+XMu6J8uabSkJHynf3KZcAH//CfWaM3yO7I8y+XYySaCz9CyBfMsmI52LVHhrxGDe/ftUlWww7ukddcp/i3M8YKXH69rFBEmv0f31Yq90navVkGPo9Hdh/9/LbWu/IctXJtqZ921S+lUF0pr3m/HPmz7TtIHhdCVi+OH5bVhapKGRJtJfIFveCYDMNDR8tr1tCq/8qZiYAMl7+f79+FdLpcTlnB+e97sm0P/Vm2s73cdb/bpwqu1VXy/9ypwk5Dqkfug7f+Ozl2h9PCNY+Bh0LWp+ur8dlG/6mjRgPw4FUx6JsS0cJXnSFHrQwYUZaWzyk8Dsy9R75bPmsMsPZrWYFRFPkuNS4JiEuQFZRTDXD27vtVXiLf6VbY6mawCPlCJyBfZM3R8iO1p5wx5q0Wqaoc3Pmf1+WL7T2zZTjxqrABj/9aVkYAGUwmXC9fCL5fLsPd6EtkF5m9TD5ur6y68QdGoLZWVggahi6LVQaT8y+XM1v+9758R200yq6Nhi8sqioXhdy+TlZ+sgbL7q7iQhme9m0DnE7ghtuBMePkNSw8LgekezzArx8BvvxYjkVJ6CbHkXi7GE4WyK8XQlY1zrlAzqwbMExes21rZVdM7k/17dHrgW5pcrE6bxeTyynD0wWXy7EsCd3kmKvKClmtWfauDEyWWBkWVI/8vips/pW23v2BX97VfGWwOdWVssKXu1+GhygLAKX+Z2VNkBWP47ny96s51ng5kDelp6yMNB4sXGEDHpkmQ9vvn5Zdt4FQdEJet7TegXk8ok7AwEMhSxUCy7fU4qRNhcEA6HXAdzsdSIrR4YkbrYgwBHFfmjUrgCUL5L/TesuBwaMv9R/o3JmOHpRjErzjeRratQn4/kvZxgFD64/v3izf/RcXyhf5SyfLXe0bj7epqQJ2bpJdMDFW2Z1naXROSZEMAsmpp9du75+fxl06+7bLMOANWhdPBG64o36GjFfpSVm1+vErGZQAGR6sCTKkGCLk9zRgCHAsV05Hzs+Tx72zprxhIbHpCu4A5Av7jyvkWJJKu3x8vV52qWUOlLN8+uXIMSCn2zUlhAzZpkj5tULIxSg3fy/HYtnLZWUqo6+8jUsEomLkzyjW2vzsq8YKT8ifW7B+N4lCBAMPdSn/3VyDj9bWYMJZkfj5ea3M4uoMm76XlZzMQV13U0BHrZyum9439BZGW/etHK90zbT6RSBbIoSsOuzaJMfiHDssKz6XXyfDDxFpHgMPdSkeVWD+h3YcLfZg1nWx6NM95FdWICKiEMAh69Sl6HUKbr00GnoFeO2bKrg8YZnXiYgowBh4qMtJSzTgyhFm5Jd58OGaaoRpkZKIiAKIgYe6pPFnRaJvigFfb3fgi02dsAkgERF1aQw81CUZ9ArunWhBRpIen6yvwfItIbi7MxERhQwGHuqyoiN1uH9yDNIS9PhgTQ2+3FqD8ioV1Q4VHpXdXEREVI+ztKjLs1er+Ot/7Cgo99+7xxqlIC1Rj56JBvRK1uPsTCMM+i46fZyIiM4IAw+FBVu1ipU7a1HlEHC4BGpdQEmFBydKPXDWrV2Xkx6BuyZYEBnB0ENEpDUMPBTWVFWgyKbif1tq8MNeJ3ol63HfpBjERrE3l4hISxh4SBOEEPh0Qw0+31iL5FgdplwUhRqHQFmVCnuNQI94PQakGZAYE2KrDRMRUUAw8JCmfLezFv9eXY2WfusTY3QY1jsCV44wI8bMKhARUbhg4CHN2X/ChcOFbsRbdEiw6BBt0uFIsRv7T7ix77gLRTYVlkgF150bhfMHGaHrqvtkERGRDwMPUQNCCKw/4MT7P1TDVi3QN8WAKRdFISOJe3YREXVlDDxEzah2qPh0fQ2+2ekAAFw4yIRrRrObi4ioq2LgIWpFXrEb73xfjf0n3IgyKbh8WCQGpBmQnmSAidPbiYi6DAYeolMQQmDjQSc++LEGpZVycUNFAVLidIgx62DQAwadguhIBQPTIjA4I4LT3omIQgwDD1EbOd0C+0+4cPSkB0eL3Th60oMap4DbI+BWAben/txeyXoM7RWBob2NyEjWc+AzEVGQMfAQBYi9WsXOoy7sPOrCrjwXqh3yv5Y1SsGAtAgAgMMlV4JOitVjRF8jBqQZuN0FEVEnYOAh6gAeVeBggRvbc13Yluv07fOl1wFGg4Iap/xvF21ScFamEYMzIjAwzYDoSHaFERF1BAYeok5Q6xRyrE9dNaegzIONB53YeMCJ46WyL0xRZFfY4IwIDGNXGBFRQDHwEAVZkc2DPcdc2J3nwt7jbl9XWFy0gqG9jMjqYUCfbgZ0s+qgMAAREbULAw9RCFFVgYOFbmw77MLWXCcK67rCACDKpKBHvB4xZgUxZh1izAp6JhqQmWJAgkV2hQkhUFYlcNLmQc9EPbvIiIjqMPAQhbAimweHC93ILXLjcKEHRXYPKmtFk73A4qIVxEXrUFDmQa1LHjMbFfxsqAmXDY1k8CEizWPgIepiVFWgyiFgq1Jx5KQHhwrdOFToRkWNipQ4PVIT9IiL1uHHvQ4U2VSYjQouHWLCqCwTUuPZLUZE2sTAQxSmPKrAuv1OfLGpBkU22TXWPU6H4X2M6BargwAghFw/yF6jwl6twl4jYI3SISc9AoN6ctYYEYUPBh6iMOdRBfYec2PrYSe2HHbCVt3yf3mDDnDXDRtSFKBPNz1G9DNhZD8j4qIZfoio62LgIdIQVQjknZTjgBRFhhq9Dog16xAbpcBsVFBSoWJXngu7jrqw+5gLDhegAOifZkB6kh61TqDGKeByC3Sz6tAzyYD0RD26WfUwRcDXZVZa4cFP+W78lO+GqgIXDzahVzJ3nSei4GDgIaIWOd0CO464sP4nB7Yfcfltn6HXAR7V/3xFASIjFBj0QEVN0z8tA9MMuHx4JAb1jOAK00TUqRh4iKhNap0CVQ45CDoyQgEUoNiuIq/Yg2MlbpRUqHC4BGqcAk4X0CNBj36pBmT1MKDGKfDV1lpsOOCER5XBKMGiQ3KsDt2seqTG69EjQY/ucTqUVao4WCAHYhdXqOgWK+/zPp6VG7MSUTsw8BBRpymt8GD1HgdOlHpw0q7ipK1+Gn1jiiL3ISuvEn7HBqYZMLq/CWf1iUCUqfnwU7+hq4DbI6fomyJYUSLSMgYeIgoaIQTsNQL5ZR7kl3pQUO5BrFmHzBS5unSkUYHDJVBQ5sGxEg+25jqx44hLVokAREcqiI5UYDHpoEKgskagokZtEqIMOiCrhwE56REYnBGBHgl6Ts8n0hgGHiLqUqpqVWw65MTuPBcqagSqagUqa1UoChBj1sESqcASqUOEATDo5HiiIpuKfcddcNWNQUqN1+G8ASaMzjIizqJDfqkH+/PlAo9JMXr072FAZncDIgwyFAkh4HQDLo+AqgKqACL04LR9oi6EgYeINMHpFth/woVtuS5sPOCUM9UARBrrd69vyKAHkmP1qHGqqKwVfgO2vZJjdeiXakDfFANS4+WCj3HROhgNrB4RhRoGHiLSHLdHYOdRF9bsc8BWJdA31YD+dZu0nrR7sO+4G/tPuHHS7vF1mUVHKjAaFOh0gF4BqhwChwrdvkUdGzIbZWVJrwP0OgUxZgXJsXp0s+qQEKODyw1UOwSqnSoqawTs1Sps1XLAd1qCHlk9DOjfIwK9kvXNzmZThaw0caYbUdsx8BARnQF7tSpnlNlVlFepKKtSUVGjwtNg0LS9RvUbfN2YKQKwRulgilBwotTjm+4fZVIwoq8Ro/sb0S/VgMJyFWv2OrBmvwOVNQJDe0fgvAEmDM5ofpq/wyVwotSDeIuOC0eS5jHwEBF1AodLoNjuQVmVCqNBQZRRgdmkIDpSJ6f5NzjvcJEb+467sPWwC8dKZF+aJVJBZa38c51g0SExRocD+W6Iuvt6JOgRZVIQbVKgCuDoSQ9OlHkghBzg3TfFgLP7GtEvxYDjpXWb0p50wxyhYGBPuZVI724G6HX+wUkIgbIqgZIKD5Jj9QxO1GUx8BARhbBjJW6s2y9np2Uk63HeABMGpBmgUxSUVHiwbr8Tmw46UVqposoh4P2LnmDRoVeyHj2TDDhR6sGOI0443f6PbY2S45e8x40GWWnyDvyucQocL/X4jXGKi1bQK9mAlDgZsLwhq5tVblzbcPySKuTMuZN2FcV2uRSBqgoM72NEelLrM+VKKjyIjFA4MJwCpksEnqeffhqLFi1CeXk5+vbti++++w5xcXGtfg0DDxFpjSoEap0y9DQOCg6XwK48F44Vu5GWaECf7gbERyvwqMChQjf2HHPhUIEbFbVyan9ljYAxQkHPRLnoY1KMDoXlKnJPuv263RpSFKCbVYeYSB3Kq1WUV6q+vdkaS4nTYWQ/I3omGWA2yopXrUtg+xEXtuc6UVCuwqDDKbvtvEoqPNhxxIUdR1wwGhRccU4kMpK4lQnVC/nA88ILL+CDDz7AG2+8gYyMDOzatQv9+vVDZGRkq1/HwENE1H5CiBYrMC63QFmVihqHQLVToLJGRX6ZB8dL5Ue1QyA+WucbO5QUq0NSjB7JsTo43AIbDzqx8YCz2e1HAFl5GtLLiJIKD/Yek9120SYFA9LkYO7+PQxQFOBwoQe5RW4cKJAhDPDf8uScvkZcPcqM1Hi93+MfL3Hju50ObDzoRFqCHhdkm3B2ptFXnap1ChSWe5Bs1bW4uCV1PSEdeDweD3r27IlVq1YhKyvrtL6WgYeIKHR5VIGDBW6UVqioccnKFABk94xAerIeugab0K77yYmNB53IK/aguVcsa5SCnIwIDO1lxKCeBhRXqPhkXQ22H3FBARBvqQtdsToU21XsPyH78LrH6VBil1WoKJOCzO4GFJR7UGyXiclkAM4dYMIlQ0xISzBACIHyKoGCcg+KbB6ctKk4afegqlagR6IevZMN6NVNj+7WprPrXG6BQpsHtU6BfqkRHXdhqUUhHXiOHDmCYcOGYebMmVi4cCHi4uLwwAMP4K677mpyrsPhgMPh8H1ut9uRnp7OwENEFCaqHSoO5LvxU74bCoDe3eVSAvGW5qswBwtc+GaHwxdiqh0CBh0wop8RYwdHIrO7HpW1Auv2O/H9HgfyyzxIidcjLUEuIbDjqAtHT8rKUUqcDmVVKhyNVvFWFBmMGq7urQCIMSuIi9YhyqSguEJFiV2FgAxZT02J64jLQ6cQ0h2cx48fh81mw8GDB5Gbm4tDhw7hsssuw4ABA3DJJZf4nTt//nzMmTMnSC0lIqKOFmXSYWhvI4b2Nrbp/L4pEeibUl9NqapVodMpMBvrqy8xZgWXDYvEZcMioQrhqywBwNWjZBXqmx0OHCp0o083ucBk9zi50W1yrB6JMTrodUBJhYrcIg9yT7pRbPegvEqgvEpFkc2DxBg9zu5rREqcDj0S/LvXqPOEdIVny5YtOPvss3HkyBFkZGQAAGbOnAkhBP7617/6ncsKDxEREbUkpCs8/fv3h9Hon+Rbymcmkwkmk6kzmkVERERdTEgPP4+Ojsb111+Pp556Cg6HA/v27cNbb72FiRMnBrtpRERE1IWEdOABgEWLFqGkpARJSUkYP348Hn/88Sbjd4iIiIhaE9JjeM4Ep6UTERGRV8hXeIiIiIjOFAMPERERhT0GHiIiIgp7DDxEREQU9hh4iIiIKOwx8BAREVHYY+AhIiKisMfAQ0RERGGPgYeIiIjCHgMPERERhT0GHiIiIgp7DDxEREQU9hh4iIiIKOwx8BAREVHYY+AhIiKisMfAQ0RERGGPgYeIiIjCHgMPERERhT0GHiIiIgp7DDxEREQU9hh4iIiIKOwx8BAREVHYY+AhIiKisMfAQ0RERGGPgYeIiIjCHgMPERERhT0GHiIiIgp7DDxEREQU9hh4iIiIKOwx8BAREVHYY+AhIiKisMfAQ0RERGGPgYeIiIjCHgMPERERhT0GHiIiIgp7DDxEREQU9hh4iIiIKOwx8BAREVHYY+AhIiKisMfAQ0RERGGPgYeIiIjCHgMPERERhT0GHiIiIgp7XSbwrFmzBjqdDk8//XSwm0JERERdTJcIPKqq4oEHHsDIkSOD3RQiIiLqggzBbkBbvPLKKxg9ejRsNluL5zgcDjgcDt/n3nPtdnuHt4+IiIgCKyYmBoqiBOzxQj7wlJaW4rnnnsOaNWvwwAMPtHje/PnzMWfOnCbH09PTO7J5RERE1AGKioqQnJwcsMcL+cDz6KOP4v7770d8fHyr582aNQsPPvig7/Py8nL06tULR48ehdVq7ehmdil2ux3p6enIy8tDbGxssJsTUnhtWsZr0zJem5bx2rSM16Z53utiNBoD+rghHXi2bNmC9evXY9GiRac812QywWQyNTlutVr5i9SC2NhYXpsW8Nq0jNemZbw2LeO1aRmvTfMC2Z0FhHjgWblyJfbv34+0tDQAclyOwWDAwYMH8eqrrwa5dURERNRVhHTg+fWvf42bbrrJ9/nvfvc7ZGVl4aGHHgpiq4iIiKirCenAExUVhaioKN/nZrMZFosFcXFxp/xak8mE2bNnN9vNpXW8Ni3jtWkZr03LeG1axmvTMl6b5nXUdVGEECKgj0hEREQUYrrEwoNEREREZ4KBh4iIiMIeAw8RERGFPQYeIiIiCnthF3j27duHK6+8EklJSUhOTsbUqVNRVlbmu7+mpgZTp05FTEwMMjIy8PbbbwextZ3v5MmTmDRpEqKiojBgwAB8/fXXwW5S0DgcDtx6663o2bMnrFYrxo4dix07dvjuf/rpp5GcnIyEhATMnDkTWhzfv2bNGuh0Ojz99NO+Y7wu8hqkp6cjJiYGw4cPR3l5ue+4lq/N5s2bMWbMGMTGxiIzMxOvvfaa7z6tXZvZs2cjOzsbOp0O77zzjt99rV2LDRs2YNiwYYiKisLFF1+MI0eOdHbTO1xL12bp0qUYPnw4YmJikJmZicWLF/t93RlfGxFm1q1bJ15//XVRXl4uKisrxQ033CBuu+023/0PP/ywuOKKK4TNZhM//PCDsFqtYt++fUFscee64YYbxB133CGqqqrExx9/LOLj40VpaWmwmxUUlZWVYu7cuSIvL0+43W7xt7/9TWRmZgohhPjiiy9ERkaGOHjwoDhx4oQYNGiQWLJkSZBb3Lk8Ho8YPXq0GDVqlJg/f74QgtdFCCGef/55cdFFF4nc3FyhqqrYsWOHqKmp4bURQuTk5IinnnpKeDwesWnTJmGxWMS+ffs0eW3efPNN8eWXX4rRo0eLt99+23e8tWtRW1srevbsKZYsWSJqamrEzJkzxYUXXhisb6HDtHRtFi9eLNasWSNcLpfYuXOn6Natm1i5cqUQIjDXJuwCT2NffvmlGDx4sO/zlJQUsXbtWt/nv/rVr8ScOXOC0bROV1FRIYxGozhx4oTv2IUXXihef/31ILYqdDgcDqEoiiguLhY33XSTePrpp333LVmyRFxyySVBbF3ne/nll8V9990nbrnlFl/g0fp1cbvdIiUlRezfv7/JfVq/NkIIYbFYxKFDh3yfjxw5Unz66aeavjYXX3yx34t6a9fif//7nxg4cKDvvsrKSmE2m0Vubm7nNbgTNb42jU2ZMkUsWLBACBGYaxN2XVqN/fjjj8jJyQEAlJWVoaCgAEOGDPHdP2zYMOzatStYzetUP/30E6xWK1JTU33HtPT9n8qaNWvQvXt3JCYmYvfu3Zr9PQGA0tJSPPfcc3jyySf9jmv9uhw7dgw1NTV4//330b17dwwYMMBXdtf6tQGAe+65B2+++SbcbjfWr1+PvLw8jB49mtemgdauReP7oqOj0bdvX+zevbvT2xlsHo8H69ev971+B+LahPRKy2dq69ateP7557Fq1SoAQGVlJfR6vd/qzbGxsaisrAxWEztVZWVlkw3qYmNjfeMPtMxms+HOO+/EvHnzADS9Vlr6PQGARx99FPfffz/i4+P9jmv9uhw/fhw2mw0HDx5Ebm4uDh06hMsuuwwDBgzQ/LUBgAkTJmDatGmYO3cuAOCVV15Bt27deG0aaO1atPQ3WovX6rHHHkNaWhrGjx8PIDDXpstVeC6//HJERkY2+/HUU0/5zjt8+DAmT56MJUuW+BKixWKBx+NBdXW17zy73Q6LxdLp30cwWCwW2O12v2Na+v5bUltbi2uuuQaTJk3CbbfdBqDptdLSddqyZQvWr1+PGTNmNLlPy9cFkNvbAHLQpdlsRk5ODn71q19h2bJlmr82JSUlmDx5Mp577jk4HA5s3boVTzzxBNatW6f5a9NQa9eCf6OlxYsX46OPPsIHH3zg2zE9ENemywWeL7/8ErW1tc1+PPbYYwCAgoICjBs3Do8//jiuueYa39fGx8cjJSXFbybOtm3bfIEo3GVlZcFms6GgoMB3TEvff3Pcbjduuukm9OjRAwsWLPAdz87O1uzvycqVK7F//36kpaUhJSUF7777LubNm4cZM2Zo+roAQP/+/WE0Gv2OiboZNlq/NocOHYLVasW1114LvV6PwYMHY+zYsVi1apXmr01DrV2LxvdVVVXh4MGDyM7O7vR2Bov3783y5cuRlJTkOx6Qa9Pu0UYhqry8XAwdOrTFgcgPPfSQmDRpkrDb7WLNmjXCarWKvXv3dnIrg+f6668Xv/71r0V1dbX45JNPND1LSwghpk+fLi6//HLhdDr9jn/++eeiV69e4tChQyI/P1/k5OSE/awSr6qqKpGfn+/7uPHGG8Uf//hHUVZWpunr4jVlyhQxY8YMUVtbK/bu3StSU1PFN998o/lrU15eLqxWq/j000+Fqqpiz549IjU1Vfz3v//V5LVxOp2ipqZGXHjhheKNN94QNTU1wuPxtHotvDORXnvtNVFbWyv+8Ic/hOUsrZauzfLly0VycrLYtm1bk68JxLUJu8CzdOlSAUBER0f7fXhVV1eLKVOmiOjoaNGzZ0/x1ltvBbG1na+oqEhcccUVwmw2i6ysLPHVV18Fu0lBk5ubKwCIyMhIv9+VVatWCSGE+NOf/iQSExNFXFycePjhh4WqqkFucXA0nKUlBK9LWVmZuO6664TFYhG9evUSL730ku8+rV+b//3vf2LYsGHCYrGI9PR0MW/ePN99Wrs2t9xyiwDg9/Htt98KIVq/FuvXrxdDhgwRkZGR4sILLwzLGVotXZuxY8cKg8Hg9/f4zjvv9H3dmV4b7pZOREREYa/LjeEhIiIiOl0MPERERBT2GHiIiIgo7DHwEBERUdhj4CEiIqKwx8BDREREYY+Bh4iIiMIeAw8RERGFPQYeIiIiCnsMPESkKdOnT4eiKBg7dmywm0JEnYiBh4iIiMIeAw8RERGFPQYeIupQqqpi4cKFGDx4MCIjIxEfH48bbrgBhw8fBgAsXboUiqJAURR88803GD58OCIjIzF06FCsXLnS77G+//57XH755bBarTCZTBg0aBAWLFgAj8fjO0cIgZdeeglnnXUWzGYzYmJiMGrUKGzdurVJ21599VX06dMHMTExuPLKK1FQUNCh14KIgiige74TETXym9/8RgAQAEROTo5ITEwUAERKSoooLCwUr732mu9+s9ksBg0aJMxmswAgoqOjxfHjx4UQQnz77bfCYDAIACI+Pl5kZWX5vu6OO+7wPd8999zjO56YmChycnKE0WgUH3/8sRBCiFtuucX3XJGRkX6PM2XKlGBcIiLqBKzwEFGHOXz4MBYvXgwAeP3117Fz507k5uaiZ8+eKCgowAsvvOB3/rPPPovdu3djw4YNMBgMqKqqwvPPPw8AmD17NtxuN3r16oVDhw5h//79+N3vfgcAWLJkCQ4dOoTc3FwsWrQIAHDdddfhxIkT2LlzJ44dO4ZzzjnH77kcDgfWrFmD/fv349prrwUAfP311x16PYgoeBh4iKjDbNy4EUIIAMAtt9wCRVEQExODY8eOAQDWrl3rd/4vf/lLAEBOTg6GDBkCANixYwcAYMOGDQCAiRMnIi4uDgAwZcoUALIba9OmTdiwYYPv+R588EEYjUYAQHJyMtLT0/2ea8iQIRg+fDgAIDs7GwBQVFQUmG+ciEKOIdgNIKLw5Q0fADB8+HCYTCa/+3v16nXaj6koyhm3C4AvNAGAwSD/FDZsLxGFF1Z4iKjDjBgxwhdQpk+fjrVr12Lt2rVYs2YNFixYgPvuu8/v/LfffhsAsGfPHl9lx1vpGTlyJADgiy++QHl5ud/5iqLgnHPOwciRI33P99xzz8HpdAIASkpKfFUlItImBh4i6jCZmZmYMWMGAOD+++9HZmYmhg4diri4OFx44YXYvHmz3/kPP/wwcnJyMGLECLjdbkRFReHee+8FAMyZMwcGgwFHjhxBZmYm+vfvj+eeew4AcPvttyMzMxO9e/fGb3/7WwDABx98gLS0NAwZMgRpaWnYuHFj533jRBRyGHiIqEO9/PLLePbZZzFkyBCcOHECR44cQe/evfHggw82We142bJlMJlMcLvdGDx4MD777DOkpaUBAMaOHYtvvvkG48aNg9vtRm5uLgYOHIi//OUvvoHRAPD8889j0aJFGD58OCorK3H48GEMHToUvXv37sTvmohCjSLYaU1EQbR06VLceuutADiGhog6Dis8REREFPYYeIiIiCjssUuLiIiIwh4rPERERBT2GHiIiIgo7DHwEBERUdhj4CEiIqKwx8BDREREYY+Bh4iIiMIeAw8RERGFPQYeIiIiCnsMPERERBT2/h+tV/9+27pWWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('apa')\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'], color='cornflowerblue',alpha=1)\n",
    "plt.plot(history.history['val_loss'],color='tomato',alpha=1)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3e67b-9101-4c01-b1df-05ca931cd82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
