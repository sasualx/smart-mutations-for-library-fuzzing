{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823ba00d-aee2-43d4-a3ed-ea90724196f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 14:17:28.493454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Concatenate, concatenate, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy, mean_squared_error\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2484e15e-6a05-450b-911f-0ad5f6aa91f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (9029, 625, 64) (9029, 625, 64)\n",
      "Validation: (1115, 625, 64) (1115, 625, 64)\n",
      "Test: (1004, 625, 64) (1004, 625, 64)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"mutations_bytemask.npz\")\n",
    "max_len = 5000\n",
    "X, Y = data['x'], data['y']\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.1)\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.1)                 \n",
    "\n",
    "\n",
    "print ('Training:', train_x.shape, train_y.shape)\n",
    "print ('Validation:', val_x.shape, val_y.shape)\n",
    "print ('Test:', test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "519a62a8-9cf9-499a-aab9-6ce08aa00581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11148, 625, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc8be17-87bc-4c1a-ae52-0805bafd1b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 14:17:57.936027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 14:17:57.950260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 14:17:57.950429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f2c816-6cdf-456d-976d-0afd923915d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 14:17:57.960635: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 14:17:57.961996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 14:17:57.962163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 14:17:57.962286: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 14:17:58.227144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 14:17:58.227449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 14:17:58.227584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 14:17:58.227684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7051 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "2023-03-08 14:17:58.228175: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 625, 64)           33024     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 625, 64)          256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 625, 100)          6500      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 625, 64)           42240     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,020\n",
      "Trainable params: 81,892\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=train_x[0].shape, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100))\n",
    "model.add(LSTM(64, input_shape=train_x[0].shape, return_sequences=True))\n",
    "model.summary()\n",
    "adam = Adam(learning_rate=0.00005)\n",
    "model.compile(optimizer=adam, loss=mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3741e62-c797-4356-b168-c004b92dc2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 14:18:05.204014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2023-03-08 14:18:05.333901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 1: val_loss improved from inf to 0.00513, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 13s 36ms/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 2/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 2: val_loss improved from 0.00513 to 0.00504, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 3/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 3: val_loss did not improve from 0.00504\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 4/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 4: val_loss did not improve from 0.00504\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 5/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 5: val_loss did not improve from 0.00504\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 6/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 6: val_loss improved from 0.00504 to 0.00501, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 7/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 7: val_loss did not improve from 0.00501\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 8/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00501 to 0.00487, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 9/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00487 to 0.00483, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 10/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00483 to 0.00480, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 11/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 11: val_loss improved from 0.00480 to 0.00460, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 12/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 12: val_loss improved from 0.00460 to 0.00455, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 13/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 13: val_loss improved from 0.00455 to 0.00445, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 14/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 14: val_loss did not improve from 0.00445\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 15/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 15: val_loss did not improve from 0.00445\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 16/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 16: val_loss did not improve from 0.00445\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 17/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 17: val_loss improved from 0.00445 to 0.00441, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 18/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 18: val_loss did not improve from 0.00441\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 19/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 19: val_loss did not improve from 0.00441\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 20/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 20: val_loss improved from 0.00441 to 0.00440, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 21/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 21: val_loss did not improve from 0.00440\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 22/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 22: val_loss improved from 0.00440 to 0.00437, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 23/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 23: val_loss did not improve from 0.00437\n",
      "283/283 [==============================] - 9s 34ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 24/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 24: val_loss did not improve from 0.00437\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 25/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 25: val_loss improved from 0.00437 to 0.00436, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 26/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 26: val_loss did not improve from 0.00436\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 27/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 27: val_loss did not improve from 0.00436\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 28/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 28: val_loss improved from 0.00436 to 0.00435, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 29/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 29: val_loss did not improve from 0.00435\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 30/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 30: val_loss improved from 0.00435 to 0.00435, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 31/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 31: val_loss did not improve from 0.00435\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 32/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 32: val_loss did not improve from 0.00435\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 33/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 33: val_loss improved from 0.00435 to 0.00434, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 34/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 34: val_loss did not improve from 0.00434\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 35/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 35: val_loss improved from 0.00434 to 0.00433, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 36/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 36: val_loss did not improve from 0.00433\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 37/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 37: val_loss did not improve from 0.00433\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 38/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 38: val_loss improved from 0.00433 to 0.00433, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 39/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 39: val_loss did not improve from 0.00433\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 40/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 40: val_loss did not improve from 0.00433\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 41/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 41: val_loss improved from 0.00433 to 0.00432, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 42/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 42: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 43/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 43: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 44/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 44: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 45/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 45: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 46/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 46: val_loss improved from 0.00432 to 0.00432, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 47/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 47: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 48/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 48: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 49/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 49: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 9s 34ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 50/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 50: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 51/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 51: val_loss improved from 0.00432 to 0.00432, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 52/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 52: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 9s 34ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 53/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 53: val_loss did not improve from 0.00432\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 54/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 54: val_loss improved from 0.00432 to 0.00430, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 55/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 55: val_loss improved from 0.00430 to 0.00430, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 56/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 56: val_loss improved from 0.00430 to 0.00429, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 57/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 57: val_loss did not improve from 0.00429\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 58/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 58: val_loss did not improve from 0.00429\n",
      "283/283 [==============================] - 9s 34ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 59/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 59: val_loss did not improve from 0.00429\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 60/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 60: val_loss did not improve from 0.00429\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 61/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 61: val_loss did not improve from 0.00429\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 62/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 62: val_loss improved from 0.00429 to 0.00428, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 63/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 63: val_loss did not improve from 0.00428\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 64/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 64: val_loss did not improve from 0.00428\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 65/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 65: val_loss improved from 0.00428 to 0.00428, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 66/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 66: val_loss did not improve from 0.00428\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 67/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 67: val_loss improved from 0.00428 to 0.00427, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 68/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 68: val_loss did not improve from 0.00427\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 69/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 69: val_loss improved from 0.00427 to 0.00426, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 70/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 70: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 71/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 71: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 72/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 72: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 73/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 73: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 74/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 74: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 75/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 75: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 76/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 76: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 77/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 77: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 78/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 78: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 79/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 79: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 80/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 80: val_loss did not improve from 0.00426\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 81/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 81: val_loss improved from 0.00426 to 0.00426, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 82/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 82: val_loss improved from 0.00426 to 0.00425, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 83/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 83: val_loss did not improve from 0.00425\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 84/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 84: val_loss did not improve from 0.00425\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 85/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 85: val_loss did not improve from 0.00425\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 86/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 86: val_loss did not improve from 0.00425\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 87/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 87: val_loss did not improve from 0.00425\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 88/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 88: val_loss improved from 0.00425 to 0.00425, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 89/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 89: val_loss did not improve from 0.00425\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 90/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 90: val_loss did not improve from 0.00425\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 91/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 91: val_loss improved from 0.00425 to 0.00424, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 92/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 92: val_loss did not improve from 0.00424\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 93/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 93: val_loss did not improve from 0.00424\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 94/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 94: val_loss did not improve from 0.00424\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 95/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 95: val_loss did not improve from 0.00424\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 96/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 96: val_loss improved from 0.00424 to 0.00424, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 97/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 97: val_loss did not improve from 0.00424\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 98/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 98: val_loss improved from 0.00424 to 0.00423, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 35ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 99/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 99: val_loss improved from 0.00423 to 0.00423, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 100/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 100: val_loss did not improve from 0.00423\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 101/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 101: val_loss improved from 0.00423 to 0.00422, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 102/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 102: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 103/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 103: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 104/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 104: val_loss improved from 0.00422 to 0.00422, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 105/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 105: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 106/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 106: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 107/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 107: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 108/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 108: val_loss improved from 0.00422 to 0.00422, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 109/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 109: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 110/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 110: val_loss improved from 0.00422 to 0.00422, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 111/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 111: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 112/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 112: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 113/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 113: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 114/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 114: val_loss did not improve from 0.00422\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 115/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 115: val_loss improved from 0.00422 to 0.00421, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 116/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 116: val_loss improved from 0.00421 to 0.00421, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 117/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 117: val_loss improved from 0.00421 to 0.00421, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 118/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 118: val_loss did not improve from 0.00421\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 119/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 119: val_loss did not improve from 0.00421\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 120/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 120: val_loss did not improve from 0.00421\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 121/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 121: val_loss did not improve from 0.00421\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 122/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 122: val_loss did not improve from 0.00421\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 123/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 123: val_loss did not improve from 0.00421\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 124/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 124: val_loss did not improve from 0.00421\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 125/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 125: val_loss did not improve from 0.00421\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 126/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 126: val_loss improved from 0.00421 to 0.00420, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 127/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 127: val_loss did not improve from 0.00420\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 128/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 128: val_loss did not improve from 0.00420\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 129/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 129: val_loss did not improve from 0.00420\n",
      "283/283 [==============================] - 10s 35ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 130/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 130: val_loss did not improve from 0.00420\n",
      "283/283 [==============================] - 10s 35ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 131/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 131: val_loss improved from 0.00420 to 0.00420, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 10s 35ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 132/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 132: val_loss did not improve from 0.00420\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 133/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 133: val_loss did not improve from 0.00420\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 134/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 134: val_loss did not improve from 0.00420\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 135/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 135: val_loss did not improve from 0.00420\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 136/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 136: val_loss did not improve from 0.00420\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 137/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 137: val_loss improved from 0.00420 to 0.00420, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 138/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 138: val_loss improved from 0.00420 to 0.00419, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 139/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 139: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 140/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 140: val_loss improved from 0.00419 to 0.00419, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 141/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 141: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 142/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 142: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 143/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 143: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 144/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 144: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 145/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 145: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 146/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 146: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 147/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 147: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 148/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 148: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 149/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 149: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 150/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 150: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 151/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 151: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 152/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 152: val_loss improved from 0.00419 to 0.00419, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 153/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 153: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 154/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 154: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 155/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 155: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 156/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 156: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 157/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 157: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 158/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 158: val_loss improved from 0.00419 to 0.00419, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 159/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 159: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 160/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 160: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 161/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 161: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 162/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 162: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 163/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 163: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 164/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 164: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 165/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 165: val_loss improved from 0.00419 to 0.00419, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 166/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 166: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 167/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 167: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 168/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 168: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 169/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 169: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 170/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 170: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 171/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 171: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 172/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 172: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 173/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 173: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 10s 34ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 174/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 174: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 175/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 175: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 176/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 176: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 177/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 177: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 178/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 178: val_loss did not improve from 0.00419\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 179/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 179: val_loss improved from 0.00419 to 0.00418, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 180/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 180: val_loss did not improve from 0.00418\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 181/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 181: val_loss did not improve from 0.00418\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 182/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 182: val_loss did not improve from 0.00418\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 183/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 183: val_loss improved from 0.00418 to 0.00418, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 184/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 184: val_loss did not improve from 0.00418\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 185/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 185: val_loss did not improve from 0.00418\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 186/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 186: val_loss did not improve from 0.00418\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 187/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 187: val_loss did not improve from 0.00418\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 188/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 188: val_loss did not improve from 0.00418\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 189/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 189: val_loss did not improve from 0.00418\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 190/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 190: val_loss improved from 0.00418 to 0.00418, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 191/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 191: val_loss improved from 0.00418 to 0.00417, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 33ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 192/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 192: val_loss improved from 0.00417 to 0.00417, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 193/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 193: val_loss improved from 0.00417 to 0.00417, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 194/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 194: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 195/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 195: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 196/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 196: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 197/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 197: val_loss improved from 0.00417 to 0.00417, saving model to best_model_lstm_checkpoint.h5\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 198/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 198: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 199/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 199: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 200/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 200: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 201/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 201: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 202/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 202: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 203/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 203: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 204/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 204: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 205/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 205: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 206/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 206: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 207/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 207: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 208/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 208: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 209/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 209: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 210/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 210: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 211/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 211: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 212/400\n",
      "283/283 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 212: val_loss did not improve from 0.00417\n",
      "283/283 [==============================] - 9s 32ms/step - loss: 0.0033 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=15)\n",
    "\n",
    "filepath = 'best_model_lstm_checkpoint.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    batch_size=32,\n",
    "                    epochs=400,\n",
    "                    validation_data=(val_x, val_y),\n",
    "                    callbacks =[es, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6bdecc-f908-47e2-9edd-82a85eb23785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004520630929619074"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model.load_weights(\"best_model_lstm_checkpoint.h5\")\n",
    "test_loss = model.evaluate(test_x, test_y)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e22a4a-b906-4726-9739-d4d2c320419b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('apa')\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'], color='cornflowerblue',alpha=1)\n",
    "plt.plot(history.history['val_loss'],color='tomato',alpha=1)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d22b9-0541-4ca2-a530-69e768f2e900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
